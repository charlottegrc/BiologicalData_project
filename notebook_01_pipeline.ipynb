{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43092396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: biopython in /Users/charlottegarcia/Library/Python/3.9/lib/python/site-packages (1.85)\n",
      "Requirement already satisfied: numpy in /Users/charlottegarcia/Library/Python/3.9/lib/python/site-packages (from biopython) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Notebook 01: PF03060 Family Pipeline (Data -> MSA -> PSSM -> HMM)\n",
    "# ---------------------------------------------------------------\n",
    "# This notebook implements the first half of the project pipeline:\n",
    "# 1) Fetch SwissProt proteins annotated with PF03060\n",
    "# 2) Extract Pfam domain sequences\n",
    "# 3) Build and clean a multiple sequence alignment (MSA)\n",
    "# 4) Build a PSSM profile model\n",
    "# 5) Build a lightweight profile HMM\n",
    "\n",
    "!pip install biopython\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO, pairwise2\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import os\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "PFAM_ID = \"PF03060\"\n",
    "OUTPUT_DIR = \"../data\"\n",
    "RESULTS_DIR = \"../results\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "533988cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching up to 150 UniProt IDs for Pfam family PF03060...\n",
      "Fetching page 1 from InterPro...\n",
      "Fetching page 2 from InterPro...\n",
      "Fetching page 3 from InterPro...\n",
      "Collected 150 UniProt IDs\n",
      "Fetching full UniProt entries via ID-mapping API...\n",
      "Submitted ID-mapping job: eAVJOPPtVL\n",
      "Downloaded 25 proteins, saved to ../data/raw_PF03060_uniprot.tsv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 1: Fetch representative UniProt SwissProt entries\n",
    "# -----------------------------\n",
    "MAX_SEQ = 150\n",
    "\n",
    "def fetch_uniprot_sample_from_pfam(pfam_id, max_entries=150, page_size=50):\n",
    "    url = f\"https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/{pfam_id}/?page_size={page_size}\"\n",
    "    results = []\n",
    "    page = 1\n",
    "\n",
    "    while url and len(results) < max_entries:\n",
    "        print(f\"Fetching page {page} from InterPro...\")\n",
    "        r = requests.get(url, headers={\"Accept\": \"application/json\"}, timeout=15)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        js = r.json()\n",
    "        for res in js.get(\"results\", []):\n",
    "            results.append(res[\"metadata\"][\"accession\"])\n",
    "            if len(results) >= max_entries:\n",
    "                break\n",
    "\n",
    "        url = js.get(\"next\")\n",
    "        page += 1\n",
    "\n",
    "    print(f\"Collected {len(results)} UniProt IDs\")\n",
    "    return results\n",
    "\n",
    "import time\n",
    "from io import StringIO\n",
    "\n",
    "def fetch_uniprot_entries_via_idmapping(uniprot_ids):\n",
    "    \"\"\"\n",
    "    Robust UniProt batch retrieval using the ID-mapping API.\n",
    "    \"\"\"\n",
    "    # 1) Submit mapping job\n",
    "    submit_url = \"https://rest.uniprot.org/idmapping/run\"\n",
    "    data = {\n",
    "        \"from\": \"UniProtKB_AC-ID\",\n",
    "        \"to\": \"UniProtKB\",\n",
    "        \"ids\": \",\".join(uniprot_ids)\n",
    "    }\n",
    "\n",
    "    r = requests.post(submit_url, data=data)\n",
    "    r.raise_for_status()\n",
    "    job_id = r.json()[\"jobId\"]\n",
    "    print(f\"Submitted ID-mapping job: {job_id}\")\n",
    "\n",
    "    # 2) Poll job status\n",
    "    status_url = f\"https://rest.uniprot.org/idmapping/status/{job_id}\"\n",
    "    while True:\n",
    "        r = requests.get(status_url)\n",
    "        r.raise_for_status()\n",
    "        js = r.json()\n",
    "        if js.get(\"jobStatus\") == \"RUNNING\":\n",
    "            print(\"ID-mapping job running...\")\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 3) Retrieve results as TSV\n",
    "    result_url = f\"https://rest.uniprot.org/idmapping/uniprotkb/results/{job_id}\"\n",
    "    params = {\n",
    "        \"format\": \"tsv\",\n",
    "        \"fields\": \"accession,sequence,organism_name,lineage,go_id\"\n",
    "    }\n",
    "\n",
    "    r = requests.get(result_url, params=params)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    df = pd.read_csv(StringIO(r.text), sep=\"\\t\")\n",
    "    return df\n",
    "\n",
    "print(f\"Fetching up to {MAX_SEQ} UniProt IDs for Pfam family {PFAM_ID}...\")\n",
    "uniprot_ids = fetch_uniprot_sample_from_pfam(PFAM_ID, max_entries=MAX_SEQ)\n",
    "\n",
    "print(\"Fetching full UniProt entries via ID-mapping API...\")\n",
    "pfam_df = fetch_uniprot_entries_via_idmapping(uniprot_ids)\n",
    "\n",
    "out_path = f\"{OUTPUT_DIR}/raw_{PFAM_ID}_uniprot.tsv\"\n",
    "pfam_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Downloaded {len(pfam_df)} proteins, saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fb1e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From', 'Entry', 'Sequence', 'Organism', 'Taxonomic lineage', 'Gene Ontology IDs']\n"
     ]
    }
   ],
   "source": [
    "#column name check \n",
    "\n",
    "print(pfam_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "387b3319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PF03060 protein sequences (full-length)...\n",
      "Extracted 25 sequences\n",
      "Saved FASTA to: ../data/PF03060_full_length.fasta\n",
      "Saved metadata to: ../data/PF03060_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 2: Extract full-length PF03060 protein sequences\n",
    "# -----------------------------\n",
    "\n",
    "def extract_pfam_sequences(df):\n",
    "    records = []\n",
    "    meta = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        acc = row[\"Entry\"]          # UniProt accession\n",
    "        seq = row[\"Sequence\"]       # Protein sequence\n",
    "\n",
    "        if pd.isna(seq) or not seq:\n",
    "            continue\n",
    "\n",
    "        rec = SeqRecord(\n",
    "            Seq(seq),\n",
    "            id=acc,\n",
    "            description=\"\"\n",
    "        )\n",
    "        records.append(rec)\n",
    "\n",
    "        meta.append({\n",
    "            \"accession\": acc,\n",
    "            \"length\": len(seq),\n",
    "            \"organism\": row.get(\"Organism\", \"\"),\n",
    "            \"lineage\": row.get(\"Taxonomic lineage\", \"\"),\n",
    "            \"go_ids\": row.get(\"Gene Ontology IDs\", \"\")\n",
    "        })\n",
    "\n",
    "    return records, pd.DataFrame(meta)\n",
    "\n",
    "\n",
    "print(\"Extracting PF03060 protein sequences (full-length)...\")\n",
    "records, domain_meta = extract_pfam_sequences(pfam_df)\n",
    "\n",
    "fasta_path = f\"{OUTPUT_DIR}/PF03060_full_length.fasta\"\n",
    "meta_path = f\"{OUTPUT_DIR}/PF03060_metadata.csv\"\n",
    "\n",
    "SeqIO.write(records, fasta_path, \"fasta\")\n",
    "domain_meta.to_csv(meta_path, index=False)\n",
    "\n",
    "print(f\"Extracted {len(records)} sequences\")\n",
    "print(f\"Saved FASTA to: {fasta_path}\")\n",
    "print(f\"Saved metadata to: {meta_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e13d2030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 25\n",
      "Min length: 224\n",
      "Max length: 415\n",
      "Mean length: 345.16\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sequences:\", len(records))\n",
    "lengths = [len(r.seq) for r in records]\n",
    "print(\"Min length:\", min(lengths))\n",
    "print(\"Max length:\", max(lengths))\n",
    "print(\"Mean length:\", sum(lengths) / len(lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO, AlignIO\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# -----------------------------\n",
    "# Folders and paths\n",
    "# -----------------------------\n",
    "INPUT_FASTA = \"../data/PF03060_full_length.fasta\"\n",
    "RESULTS_DIR = Path(\"../results\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MSA_RAW = RESULTS_DIR / \"PF03060.aln.fasta\"\n",
    "MSA_CLEAN = RESULTS_DIR / \"PF03060.cleaned.aln.fasta\"\n",
    "PSSM_FILE = RESULTS_DIR / \"PF03060.pssm.txt\"\n",
    "HMM_FILE = RESULTS_DIR / \"PF03060.hmm\"\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 3: Build MSA via Clustal Omega\n",
    "# -----------------------------\n",
    "print(\"Running Clustal Omega to generate MSA...\")\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [\"clustalo\", \"-i\", INPUT_FASTA, \"-o\", str(MSA_RAW), \"--force\", \"--threads=4\"],\n",
    "        check=True\n",
    "    )\n",
    "    print(\"MSA generated:\", MSA_RAW)\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Error: Clustal Omega failed. Make sure it is installed and in your PATH.\")\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 3b: Clean MSA (remove columns >50% gaps)\n",
    "# -----------------------------\n",
    "print(\"Cleaning MSA (removing highly gappy columns)...\")\n",
    "alignment = AlignIO.read(MSA_RAW, \"fasta\")\n",
    "seqs = np.array([list(str(rec.seq)) for rec in alignment])\n",
    "keep_cols = [i for i in range(seqs.shape[1]) if np.mean(seqs[:, i] == '-') < 0.5]\n",
    "\n",
    "cleaned_records = []\n",
    "for rec in alignment:\n",
    "    new_seq = ''.join([rec.seq[i] for i in keep_cols])\n",
    "    rec.seq = new_seq\n",
    "    cleaned_records.append(rec)\n",
    "\n",
    "AlignIO.write(cleaned_records, MSA_CLEAN, \"fasta\")\n",
    "print(\"Cleaned MSA saved:\", MSA_CLEAN)\n",
    "print(\"Cleaned MSA length:\", len(cleaned_records[0].seq))\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 4: Build PSSM\n",
    "# -----------------------------\n",
    "print(\"Building crude PSSM from cleaned MSA...\")\n",
    "seq_array = np.array([list(str(r.seq)) for r in cleaned_records])\n",
    "pssm = []\n",
    "\n",
    "for col in range(seq_array.shape[1]):\n",
    "    counts = Counter(seq_array[:, col])\n",
    "    total = sum(counts.values())\n",
    "    freqs = {aa: counts.get(aa, 0)/total for aa in \"ACDEFGHIKLMNPQRSTVWY-\"}\n",
    "    pssm.append(freqs)\n",
    "\n",
    "# Save PSSM\n",
    "with open(PSSM_FILE, \"w\") as f:\n",
    "    f.write(\"\\t\".join([\"Pos\"] + list(\"ACDEFGHIKLMNPQRSTVWY-\")) + \"\\n\")\n",
    "    for i, col in enumerate(pssm, 1):\n",
    "        f.write(f\"{i}\\t\" + \"\\t\".join(f\"{col[aa]:.3f}\" for aa in \"ACDEFGHIKLMNPQRSTVWY-\") + \"\\n\")\n",
    "print(\"PSSM saved to:\", PSSM_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 5: Build HMM via HMMER\n",
    "# -----------------------------\n",
    "print(\"Building HMM from cleaned MSA using hmmbuild...\")\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [\"hmmbuild\", str(HMM_FILE), str(MSA_CLEAN)],\n",
    "        check=True\n",
    "    )\n",
    "    print(\"HMM saved to:\", HMM_FILE)\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Error: HMMER hmmbuild failed. Make sure hmmbuild is installed and in your PATH.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d0ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b41046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# STEP 3: Build MSA (python version - old)\n",
    "# -----------------------------\n",
    "\n",
    "print(\"Building crude MSA using seed-based alignment\")\n",
    "seed_seq = records[0].seq\n",
    "aligned_records = []\n",
    "\n",
    "for rec in records:\n",
    "    alns = pairwise2.align.globalxx(seed_seq, rec.seq)\n",
    "    best = alns[0]\n",
    "    aligned_seed, aligned_seq = best.seqA, best.seqB\n",
    "    aligned_records.append(SeqRecord(Seq(aligned_seq), id=rec.id, description=\"\"))\n",
    "\n",
    "SeqIO.write(aligned_records, f\"{OUTPUT_DIR}/pf03060_msa_raw.fasta\", \"fasta\")\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 3b: Clean MSA (remove gappy columns)\n",
    "# -----------------------------\n",
    "\n",
    "def clean_msa(records, gap_thresh=0.5):\n",
    "    seqs = np.array([list(str(r.seq)) for r in records])\n",
    "    keep_cols = []\n",
    "    for i in range(seqs.shape[1]):\n",
    "        col = seqs[:, i]\n",
    "        gap_frac = np.mean(col == '-')\n",
    "        if gap_frac < gap_thresh:\n",
    "            keep_cols.append(i)\n",
    "    cleaned = []\n",
    "    for r in records:\n",
    "        new_seq = ''.join([str(r.seq)[i] for i in keep_cols])\n",
    "        cleaned.append(SeqRecord(Seq(new_seq), id=r.id, description=\"\"))\n",
    "    return cleaned\n",
    "\n",
    "msa_clean = clean_msa(aligned_records)\n",
    "SeqIO.write(msa_clean, f\"{OUTPUT_DIR}/pf03060_msa_clean.fasta\", \"fasta\")\n",
    "print(\"Cleaned MSA length:\", len(msa_clean[0].seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aaa279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# STEP 4: Build a PSSM - Python (old)\n",
    "# -----------------------------\n",
    "\n",
    "print(\"Building PSSM from cleaned MSA\")\n",
    "\n",
    "AA_LIST = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "bg_freq = {aa: 1/20 for aa in AA_LIST}\n",
    "\n",
    "msa_array = np.array([list(str(r.seq)) for r in msa_clean])\n",
    "\n",
    "pssm = []\n",
    "\n",
    "for i in range(msa_array.shape[1]):\n",
    "    col = msa_array[:, i]\n",
    "    counts = Counter(col)\n",
    "    total = sum(counts[aa] for aa in counts if aa != '-') + 20  # pseudocounts\n",
    "    col_scores = {}\n",
    "    for aa in AA_LIST:\n",
    "        freq = (counts.get(aa, 0) + 1) / total\n",
    "        col_scores[aa] = math.log2(freq / bg_freq[aa])\n",
    "    pssm.append(col_scores)\n",
    "\n",
    "pssm_df = pd.DataFrame(pssm)\n",
    "pssm_df.to_csv(f\"{RESULTS_DIR}/pssm_matrix.csv\", index=False)\n",
    "print(\"PSSM saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# STEP 5: Build lightweight profile HMM - Python (old)\n",
    "# -----------------------------\n",
    "\n",
    "print(\"Building lightweight profile HMM\")\n",
    "\n",
    "hmm = []\n",
    "\n",
    "for i in range(msa_array.shape[1]):\n",
    "    col = msa_array[:, i]\n",
    "    counts = Counter(col)\n",
    "    total = sum(counts[aa] for aa in counts if aa != '-') + 20\n",
    "    emissions = {}\n",
    "    for aa in AA_LIST:\n",
    "        emissions[aa] = (counts.get(aa, 0) + 1) / total\n",
    "    hmm.append(emissions)\n",
    "\n",
    "import json\n",
    "with open(f\"{RESULTS_DIR}/hmm_params.json\", \"w\") as f:\n",
    "    json.dump(hmm, f, indent=2)\n",
    "\n",
    "print(\"HMM parameters saved\")\n",
    "print(\"Notebook 01 complete: Data -> MSA -> PSSM -> HMM\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
