{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Preparation**"
      ],
      "metadata": {
        "id": "kJb34Cpz1i6t"
      },
      "id": "kJb34Cpz1i6t"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "gVC6-TCkRGzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e9e737-9958-48bc-8857-bb558dc1ebfd"
      },
      "id": "gVC6-TCkRGzo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Biologicaldata_Project'"
      ],
      "metadata": {
        "id": "fuR2TfhFRHdf"
      },
      "id": "fuR2TfhFRHdf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "id": "f_QNDcs8RA6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f986f8-5705-44fd-c25d-05c9ac59732f"
      },
      "id": "f_QNDcs8RA6e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "339c26af",
      "metadata": {
        "id": "339c26af"
      },
      "outputs": [],
      "source": [
        "from Bio import SeqIO\n",
        "from Bio.Blast import NCBIXML\n",
        "import pandas as pd\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e55f32a7",
      "metadata": {
        "id": "e55f32a7"
      },
      "source": [
        "# Generating the MSA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 -  Starting from the BLAST pairwise alignments processing the provided XML file.\n"
      ],
      "metadata": {
        "id": "QN4VXv5Ocutu"
      },
      "id": "QN4VXv5Ocutu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate the provided XML File, we searched the UNiref50 Database for up to 1000 Alignments and AlignViews BLASTXML.\n",
        "Our Protein Sequence has the UniProt Id: Q12723 and the Pfam Id: Pfam03060"
      ],
      "metadata": {
        "id": "yLapQRUG10E6"
      },
      "id": "yLapQRUG10E6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf4b485c",
      "metadata": {
        "id": "bf4b485c",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "862b0496-20c1-44cb-f22a-d8e3298d3740"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "query_id                                                EMBOSS_001\n",
              "subject_id       UR50:UniRef50_A0A804M4U7 glutaredoxin-dependen...\n",
              "query_len                                                      161\n",
              "query_seq          KKVILFALPGAFTPVCSARHVPEYIEKLPEIRAKGVDVVAVLAYNDA\n",
              "match_seq          KKV+LFA+ G F P C+ +H+   + K+ E  AKG+D VA +  NDA\n",
              "subject_seq        KKVVLFAMSGTFMPTCTHKHLLGSMVKVGEFHAKGIDTVACVPVNDA\n",
              "query_start                                                     42\n",
              "query_end                                                       88\n",
              "subject_start                                                   98\n",
              "subject_end                                                    144\n",
              "identity                                                        22\n",
              "positive                                                        31\n",
              "gaps                                                             0\n",
              "eval                                                      0.000078\n",
              "bit_score                                                    116.0\n",
              "Name: 999, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>query_id</th>\n",
              "      <td>EMBOSS_001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subject_id</th>\n",
              "      <td>UR50:UniRef50_A0A804M4U7 glutaredoxin-dependen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query_len</th>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query_seq</th>\n",
              "      <td>KKVILFALPGAFTPVCSARHVPEYIEKLPEIRAKGVDVVAVLAYNDA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>match_seq</th>\n",
              "      <td>KKV+LFA+ G F P C+ +H+   + K+ E  AKG+D VA +  NDA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subject_seq</th>\n",
              "      <td>KKVVLFAMSGTFMPTCTHKHLLGSMVKVGEFHAKGIDTVACVPVNDA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query_start</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query_end</th>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subject_start</th>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subject_end</th>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>identity</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gaps</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval</th>\n",
              "      <td>0.000078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bit_score</th>\n",
              "      <td>116.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "# Parse the XML output\n",
        "# https://www.biostars.org/p/82514/\n",
        "\n",
        "input_file = '{}/data/O43099_Uniref50_1000.xml'.format(data_dir)\n",
        "\n",
        "with open(input_file) as f:\n",
        "  blast_records = NCBIXML.parse(f)\n",
        "  data = []\n",
        "\n",
        "  # Iterate PSIBLAST rounds (here just one since it is a simple BLAST)\n",
        "  for blast_record in blast_records:\n",
        "      query_id = blast_record.query\n",
        "\n",
        "      # Iterate alignments objects\n",
        "      for i, alignment in enumerate(blast_record.alignments):\n",
        "          subject_id = alignment.title\n",
        "\n",
        "          # Iterate pairwise alignments (High scoring pairs - HPS)\n",
        "          for hsp in alignment.hsps:\n",
        "              data.append((query_id,\n",
        "                              subject_id,\n",
        "                              blast_record.query_length,\n",
        "                              hsp.query,\n",
        "                              hsp.match,\n",
        "                              hsp.sbjct,\n",
        "                              hsp.query_start,\n",
        "                              hsp.query_end,\n",
        "                              hsp.sbjct_start,\n",
        "                              hsp.sbjct_end,\n",
        "                              hsp.identities,\n",
        "                              hsp.positives,\n",
        "                              hsp.gaps,\n",
        "                              hsp.expect,\n",
        "                              hsp.score))\n",
        "\n",
        "              # Skip duplicated subjects\n",
        "              break\n",
        "\n",
        "# Build a dataframe\n",
        "df = pd.DataFrame(data, columns=[\"query_id\", \"subject_id\", \"query_len\",\n",
        "                                  \"query_seq\", \"match_seq\", \"subject_seq\",\n",
        "                                \"query_start\", \"query_end\", \"subject_start\", \"subject_end\",\n",
        "                                \"identity\", \"positive\", \"gaps\", \"eval\", \"bit_score\"])\n",
        "# Print an example\n",
        "len(df)\n",
        "df.iloc[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b254d9",
      "metadata": {
        "id": "62b254d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94e944f-382c-44fa-83a7-f1477a2bbb97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote combined FASTA (query first): /content/drive/MyDrive/BioInformatics/final/data/O43099_Uniref50_1000.fasta\n",
            "Total rows in df: 1000\n"
          ]
        }
      ],
      "source": [
        "# Extract the sequence of aligned subject proteins (hits) and create the .fasta file\n",
        "# Filter hits based on an e-value threshold\n",
        "#We dont create the further produced MSA here yet\n",
        "\n",
        "out_file = '{}/data/O43099_Uniref50_1000.fasta'.format(data_dir)\n",
        "\n",
        "# ✅ set your query header + sequence here\n",
        "query_id = \"O43099_TIR\"\n",
        "query_seq = \"KAGDSFPSDVVFSYIPWSEDKGEITACGIPINYNASKEWADKKVILFALPGAFTPVCSARHVPEYIEKLPEIRAKGVDVVAVLAYNDAYVMSAWGKANQVTGDDILFLSDPDARFSKSIGWADEEGRTKRYALVIDHGKITYAALEPAKNHLEFSSAETVL\"\n",
        "\n",
        "with open(out_file, \"w\") as fout:\n",
        "    # 1) write query/reference first\n",
        "    fout.write(f\">{query_id}\\n{query_seq}\\n\")\n",
        "\n",
        "    # 2) write mapped BLAST hits (query-length with gaps)\n",
        "    for index, row in df.iterrows():\n",
        "        if row[\"eval\"] < 0.001:\n",
        "            mapped_seq = [\"-\"] * blast_record.query_length\n",
        "            c = 0\n",
        "            for l_q, l_s in zip(row['query_seq'], row['subject_seq']):\n",
        "                if l_q != \" \" and l_q != '-':\n",
        "                    mapped_seq[row[\"query_start\"] + c - 1] = l_s if l_s != \" \" else \"-\"\n",
        "                    c += 1\n",
        "            fout.write(\">{}\\n{}\\n\".format(row[\"subject_id\"], \"\".join(mapped_seq)))\n",
        "\n",
        "print(\"✅ Wrote combined FASTA (query first):\", out_file)\n",
        "print(\"Total rows in df:\", len(df))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparation Step- Build a fasta with only our given rpotein sequence\n",
        "query_file = f\"{data_dir}/data/O43099_reference_query.fasta\"\n",
        "\n",
        "with open(query_file, \"w\") as f:\n",
        "    f.write(\">O43099_TIR\\n\")\n",
        "    f.write(\"KAGDSFPSDVVFSYIPWSEDKGEITACGIPINYNASKEWADKKVILFALPGAFTPVCSARHVPEYIEKLPEIRAKGVDVVAVLAYNDAYVMSAWGKANQVTGDDILFLSDPDARFSKSIGWADEEGRTKRYALVIDHGKITYAALEPAKNHLEFSSAETVL\\n\")"
      ],
      "metadata": {
        "id": "HzYMwkclSaiS"
      },
      "id": "HzYMwkclSaiS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build MSA from that joined fasta\n",
        "# Install clustalo\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install -y clustalo\n",
        "\n",
        "msa_raw = f\"{data_dir}/data/O43099_raw_msa.fasta\"\n",
        "\n",
        "# --output-order=input-order keeps query first\n",
        "!clustalo -i \"{out_file}\" -o \"{msa_raw}\" --force --outfmt=fasta --output-order=input-order\n",
        "\n",
        "print(\"✅ MSA written:\", msa_raw)\n"
      ],
      "metadata": {
        "id": "wAfB0tVqP0Bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9df686-62c5-4b4f-a1cd-eab93af8902e"
      },
      "id": "wAfB0tVqP0Bj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "✅ MSA written: /content/drive/MyDrive/BioInformatics/final/data/O43099_raw_msa.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean that new MSA\n",
        "!pip -q install biopython\n",
        "\n",
        "from Bio import SeqIO\n",
        "from collections import Counter\n",
        "import re, os\n",
        "\n",
        "msa_in  = msa_raw\n",
        "msa_out = f\"{data_dir}/data/O43099_final_msa.fasta\"\n",
        "\n",
        "MAX_GAP_FRAC_PER_SEQ = 0.60\n",
        "MAX_GAP_FRAC_PER_COL = 0.50\n",
        "DEDUPLICATE_SEQS     = True\n",
        "\n",
        "ALLOWED = set(list(\"ACDEFGHIKLMNPQRSTVWYXBZUOJU-\"))\n",
        "\n",
        "def normalize_seq(s: str) -> str:\n",
        "    s = s.upper().replace(\".\", \"-\")\n",
        "    s = re.sub(r\"\\s+\", \"\", s)\n",
        "    s = \"\".join((c if c in ALLOWED else \"X\") for c in s)\n",
        "    return s\n",
        "\n",
        "records = list(SeqIO.parse(msa_in, \"fasta\"))\n",
        "if not records:\n",
        "    raise ValueError(f\"No sequences found in {msa_in}\")\n",
        "\n",
        "# normalize + enforce equal length\n",
        "for r in records:\n",
        "    r.seq = type(r.seq)(normalize_seq(str(r.seq)))\n",
        "\n",
        "L = max(len(r) for r in records)\n",
        "for r in records:\n",
        "    s = str(r.seq)\n",
        "    if len(s) < L:\n",
        "        s += \"-\" * (L - len(s))\n",
        "    elif len(s) > L:\n",
        "        s = s[:L]\n",
        "    r.seq = type(r.seq)(s)\n",
        "\n",
        "def gap_frac(seq: str) -> float:\n",
        "    return seq.count(\"-\") / len(seq)\n",
        "\n",
        "# keep query (first record) even if gappy; filter others\n",
        "filtered = [records[0]] + [r for r in records[1:] if gap_frac(str(r.seq)) <= MAX_GAP_FRAC_PER_SEQ]\n",
        "records = filtered\n",
        "\n",
        "# deduplicate identical aligned sequences\n",
        "if DEDUPLICATE_SEQS:\n",
        "    seen = set()\n",
        "    dedup = []\n",
        "    for r in records:\n",
        "        s = str(r.seq)\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            dedup.append(r)\n",
        "    records = dedup\n",
        "\n",
        "seqs = [str(r.seq) for r in records]\n",
        "L = len(seqs[0])\n",
        "\n",
        "# column mask (gap filter)\n",
        "keep_mask = []\n",
        "for col in range(L):\n",
        "    colchars = [s[col] for s in seqs]\n",
        "    gap_f = colchars.count(\"-\") / len(colchars)\n",
        "    keep_mask.append(gap_f <= MAX_GAP_FRAC_PER_COL)\n",
        "\n",
        "kept_cols = [i for i, k in enumerate(keep_mask) if k]\n",
        "if len(kept_cols) < 10:\n",
        "    raise ValueError(\"Too many columns removed — relax MAX_GAP_FRAC_PER_COL.\")\n",
        "\n",
        "def apply_mask(seq: str, cols):\n",
        "    return \"\".join(seq[i] for i in cols)\n",
        "\n",
        "for r in records:\n",
        "    r.seq = type(r.seq)(apply_mask(str(r.seq), kept_cols))\n",
        "\n",
        "os.makedirs(os.path.dirname(msa_out), exist_ok=True)\n",
        "SeqIO.write(records, msa_out, \"fasta\")\n",
        "\n",
        "print(\"✅ Cleaned MSA written:\", msa_out)\n",
        "print(\"Sequences:\", len(records))\n",
        "print(\"Alignment length:\", len(records[0].seq))\n",
        "print(\"Query first:\", records[0].id)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MFD8iWZzP-zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5406a08-7950-4613-e5ce-b7dcb7a1717f"
      },
      "id": "MFD8iWZzP-zm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cleaned MSA written: /content/drive/MyDrive/BioInformatics/final/data/O43099_final_msa.fasta\n",
            "Sequences: 920\n",
            "Alignment length: 125\n",
            "Query first: O43099_TIR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Model Construction**"
      ],
      "metadata": {
        "id": "5Qz19aVlmYjn"
      },
      "id": "5Qz19aVlmYjn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building The HMM Model**"
      ],
      "metadata": {
        "id": "gL7KbBEs3HwD"
      },
      "id": "gL7KbBEs3HwD"
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the HMM\n",
        "!apt-get update -qq\n",
        "!apt-get install -y hmmer"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yguNPhTy0LY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c8de73-902f-4844-e151-fc5ca5aac589"
      },
      "id": "yguNPhTy0LY3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "hmmer is already the newest version (3.3.2+dfsg-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 79 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hmmbuild -h | head\n",
        "!hmmsearch -h | head"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CzIEW08h0WfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d689f780-9e31-45b7-dc58-8d6a26fc2659"
      },
      "id": "CzIEW08h0WfL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# hmmbuild :: profile HMM construction from multiple sequence alignments\n",
            "# HMMER 3.3.2 (Nov 2020); http://hmmer.org/\n",
            "# Copyright (C) 2020 Howard Hughes Medical Institute.\n",
            "# Freely distributed under the BSD open source license.\n",
            "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "Usage: hmmbuild [-options] <hmmfile_out> <msafile>\n",
            "\n",
            "Basic options:\n",
            "  -h     : show brief help on version and usage\n",
            "  -n <s> : name the HMM <s>\n",
            "# hmmsearch :: search profile(s) against a sequence database\n",
            "# HMMER 3.3.2 (Nov 2020); http://hmmer.org/\n",
            "# Copyright (C) 2020 Howard Hughes Medical Institute.\n",
            "# Freely distributed under the BSD open source license.\n",
            "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "Usage: hmmsearch [options] <hmmfile> <seqdb>\n",
            "\n",
            "Basic options:\n",
            "  -h : show brief help on version and usage\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y ncbi-blast+\n",
        "!psiblast -h | head"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bde4_afT0bef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baec1698-b328-4c53-f6a6-04a986e41b7b"
      },
      "id": "bde4_afT0bef",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ncbi-blast+ is already the newest version (2.12.0+ds-3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 79 not upgraded.\n",
            "USAGE\n",
            "  psiblast [-h] [-help] [-import_search_strategy filename]\n",
            "    [-export_search_strategy filename] [-db database_name]\n",
            "    [-dbsize num_letters] [-gilist filename] [-seqidlist filename]\n",
            "    [-negative_gilist filename] [-negative_seqidlist filename]\n",
            "    [-taxids taxids] [-negative_taxids taxids] [-taxidlist filename]\n",
            "    [-negative_taxidlist filename] [-ipglist filename]\n",
            "    [-negative_ipglist filename] [-entrez_query entrez_query]\n",
            "    [-subject subject_input_file] [-subject_loc range] [-query input_file]\n",
            "    [-out output_file] [-evalue evalue] [-word_size int_value]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install -y ncbi-blast+"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EEPwGDsv2cNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b96a0f-495c-4fae-8ba6-4d64182badea"
      },
      "id": "EEPwGDsv2cNI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ncbi-blast+ is already the newest version (2.12.0+ds-3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 79 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hmmbuild \"{data_dir}/data/O43099_Uniref50_1000.hmm\" \"{data_dir}/data/O43099_final_msa.fasta\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "adO6UxYQ0lly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "770e9f1d-ab59-4371-913e-65bea8719e63"
      },
      "id": "adO6UxYQ0lly",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# hmmbuild :: profile HMM construction from multiple sequence alignments\n",
            "# HMMER 3.3.2 (Nov 2020); http://hmmer.org/\n",
            "# Copyright (C) 2020 Howard Hughes Medical Institute.\n",
            "# Freely distributed under the BSD open source license.\n",
            "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "# input alignment file:             /content/drive/MyDrive/BioInformatics/final/data/O43099_final_msa.fasta\n",
            "# output HMM file:                  /content/drive/MyDrive/BioInformatics/final/data/O43099_Uniref50_1000.hmm\n",
            "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\n",
            "# idx name                  nseq  alen  mlen eff_nseq re/pos description\n",
            "#---- -------------------- ----- ----- ----- -------- ------ -----------\n",
            "1     O43099_final_msa       920   125   124     3.78  0.590 \n",
            "\n",
            "# CPU time: 0.09u 0.00s 00:00:00.09 Elapsed: 00:00:00.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the PSSM Model**"
      ],
      "metadata": {
        "id": "a2Fa3NAoQQLJ"
      },
      "id": "a2Fa3NAoQQLJ"
    },
    {
      "cell_type": "code",
      "source": [
        "db_fasta = f\"{data_dir}/data/protFamily_db_ungapped.fasta\"\n",
        "db_name  = f\"{data_dir}/data/blastdb/protFamily_db_ungapped\"\n",
        "\n",
        "# make ungapped DB sequences (BLAST DB should not contain '-')\n",
        "recs = []\n",
        "for rec in SeqIO.parse(out_file, \"fasta\"):\n",
        "    rec.seq = type(rec.seq)(str(rec.seq).replace(\"-\", \"\"))\n",
        "    recs.append(rec)\n",
        "\n",
        "SeqIO.write(recs, db_fasta, \"fasta\")\n",
        "\n",
        "!makeblastdb -in \"{db_fasta}\" -dbtype prot -out \"{db_name}\"\n",
        "print(\"✅ BLAST DB built:\", db_name)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EfGg_aMuQUL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77fde48c-e61b-4af8-bfd6-b2baa9a831f4"
      },
      "id": "EfGg_aMuQUL5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Building a new DB, current time: 02/18/2026 23:34:12\n",
            "New DB name:   /content/drive/MyDrive/BioInformatics/final/data/blastdb/protFamily_db_ungapped\n",
            "New DB title:  /content/drive/MyDrive/BioInformatics/final/data/protFamily_db_ungapped.fasta\n",
            "Sequence type: Protein\n",
            "Keep MBits: T\n",
            "Maximum file size: 1000000000B\n",
            "Adding sequences from FASTA; added 1001 sequences in 0.125441 seconds.\n",
            "\n",
            "\n",
            "✅ BLAST DB built: /content/drive/MyDrive/BioInformatics/final/data/blastdb/protFamily_db_ungapped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build final pssm\n",
        "clean_msa = f\"{data_dir}/data/O43099_final_msa.fasta\"\n",
        "pssm_out  = f\"{data_dir}/data/O43099_Uniref50_1000.pssm\"\n",
        "log_out   = f\"{data_dir}/data/O43099_pssm.log\"\n",
        "\n",
        "!psiblast \\\n",
        "  -in_msa \"{clean_msa}\" \\\n",
        "  -db \"{db_name}\" \\\n",
        "  -num_iterations 1 \\\n",
        "  -out_pssm \"{pssm_out}\" \\\n",
        "  -out \"{log_out}\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "wcwzUJfvQhXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d1ef7db-81c2-48ab-99a6-25f9897356cc"
      },
      "id": "wcwzUJfvQhXM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: [psiblast] O43099_TIR: Composition-based score adjustment conditioned on sequence properties and unconditional composition-based score adjustment is not supported with PSSMs, resetting to default value of standard composition-based statistics \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Generating Model Predictions against SwissProt**\n"
      ],
      "metadata": {
        "id": "tVSYmd1PmltO"
      },
      "id": "tVSYmd1PmltO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "PSSM in Swissprot"
      ],
      "metadata": {
        "id": "p8-y139CQ5AS"
      },
      "id": "p8-y139CQ5AS"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\n",
        "!gunzip uniprot_sprot.fasta.gz\n",
        "!makeblastdb -in uniprot_sprot.fasta -dbtype prot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cwdnVI6cQ7lf",
        "outputId": "04d78ab5-615c-4c14-bbea-bc45fd3deccd"
      },
      "id": "cwdnVI6cQ7lf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-18 23:24:32--  https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\n",
            "Resolving ftp.uniprot.org (ftp.uniprot.org)... 128.175.240.195\n",
            "Connecting to ftp.uniprot.org (ftp.uniprot.org)|128.175.240.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93457057 (89M) [application/x-gzip]\n",
            "Saving to: ‘uniprot_sprot.fasta.gz’\n",
            "\n",
            "uniprot_sprot.fasta 100%[===================>]  89.13M   156MB/s    in 0.6s    \n",
            "\n",
            "2026-02-18 23:24:33 (156 MB/s) - ‘uniprot_sprot.fasta.gz’ saved [93457057/93457057]\n",
            "\n",
            "gzip: uniprot_sprot.fasta already exists; do you wish to overwrite (y or n)? ^C\n",
            "\n",
            "\n",
            "Building a new DB, current time: 02/18/2026 23:32:42\n",
            "New DB name:   /content/uniprot_sprot.fasta\n",
            "New DB title:  uniprot_sprot.fasta\n",
            "Sequence type: Protein\n",
            "Deleted existing Protein BLAST database named /content/uniprot_sprot.fasta\n",
            "Keep MBits: T\n",
            "Maximum file size: 1000000000B\n",
            "Adding sequences from FASTA; added 574627 sequences in 16.9037 seconds.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we run hmm against swiss prot\n",
        "#tblout for protein matching\n",
        "#domtblout for position matching\n",
        "!hmmsearch \\\n",
        "  --tblout \"{data_dir}/data/O43099_hmm_vs_swissprot.tbl\" \\\n",
        "  --domtblout \"{data_dir}/data/O43099_hmm_vs_swissprot.domtbl\" \\\n",
        "  \"{data_dir}/data/O43099_Uniref50_1000.hmm\"\\\n",
        "  uniprot_sprot.fasta"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PdtFQseIVUwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d26e43-c1eb-474a-bde9-8ea7657838aa"
      },
      "id": "PdtFQseIVUwY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Error: File existence/permissions problem in trying to open HMM file /content/drive/MyDrive/BioInformatics/final/data/O43099_Uniref50_1000.hmm.\n",
            "HMM file /content/drive/MyDrive/BioInformatics/final/data/O43099_Uniref50_1000.hmm not found (nor an .h3m binary of it)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we collect the nessecary columns sstart/send to get the proteins position\n",
        "!psiblast \\\n",
        "  -in_pssm \"{data_dir}/data/O43099_Uniref50_1000.pssm\" \\\n",
        "  -db uniprot_sprot.fasta \\\n",
        "  -outfmt \"6 sseqid qstart qend sstart send evalue bitscore length pident\" \\\n",
        "  -out \"{data_dir}/data/O43099_pssm_vs_swissprot.tsv\""
      ],
      "metadata": {
        "id": "_zZ-qNHkUBTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1581aef-2d58-44e0-9184-46e0f5bbe5b1"
      },
      "id": "_zZ-qNHkUBTO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command line argument error: Argument \"in_pssm\". File is not accessible:  `/content/drive/MyDrive/BioInformatics/final/data/O43099_Uniref50_1000.pssm'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of what we have now:\n",
        "\n",
        "Collect the list of retrieved hits:\n",
        "pssm -> sseqid in TSV \"Q12723_pssm_vs_swissprot.tsv\"\n",
        "hmm- ->  targets in domtbl\n",
        "\n",
        "Collect matching positions in retrieved hits\n",
        "pssm -> sstart/send\n",
        "hmm -> domtbl Koordinaten \"Q12723_hmm_vs_swissprot.domtbl\""
      ],
      "metadata": {
        "id": "kTM4eajUeyze"
      },
      "id": "kTM4eajUeyze"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Search Results Ground Truth - From our Pfam Id**\n"
      ],
      "metadata": {
        "id": "h9LZN9E4dnZ0"
      },
      "id": "h9LZN9E4dnZ0"
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we check for our Pfam Annotations in the swiss prot database, from the provided TSV with only reviewd proteins\n",
        "# We also pritn out all annotation for later calculations.\n",
        "import pandas as pd\n",
        "\n",
        "path = f\"{data_dir}/data/protein2ipr_sprot.dat\"\n",
        "df = pd.read_csv(path, sep=\"\\t\", header=None)\n",
        "\n",
        "pfam_id = \"PF08534\"\n",
        "\n",
        "# All proteins in SwissProt annotation file\n",
        "all_swissprot = set(df[0])\n",
        "\n",
        "# Ground truth proteins for this Pfam\n",
        "ground_truth = set(df[df[3] == pfam_id][0])\n",
        "\n",
        "print(\"Total SwissProt proteins:\", len(all_swissprot))\n",
        "print(\"Ground truth proteins (PF08534):\", len(ground_truth))\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dxRt_WkihtFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc07578-9caa-43a2-a74f-fb1930e3be56"
      },
      "id": "dxRt_WkihtFW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total SwissProt proteins: 534419\n",
            "Ground truth proteins (PF08534): 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmFmQzLG7n3Y"
      },
      "id": "wmFmQzLG7n3Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_proteins = set(pfam_hits[0])\n",
        "\n",
        "print(\"Ground truth proteins:\", len(ground_truth_proteins))"
      ],
      "metadata": {
        "id": "mXnWm4A5mOoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1d4b0c-b4be-4c8d-d37c-b0f72859a768"
      },
      "id": "mXnWm4A5mOoW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground truth proteins: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Search Result Processing - pssm**"
      ],
      "metadata": {
        "id": "fc_uFK3Md8-I"
      },
      "id": "fc_uFK3Md8-I"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pssm_path = f\"{data_dir}/data/O43099_pssm_vs_swissprot.tsv\"\n",
        "\n",
        "pssm_df = pd.read_csv(\n",
        "    pssm_path,\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    names=[\"sseqid\",\"qstart\",\"qend\",\"sstart\",\"send\",\"evalue\",\"bitscore\",\"length\",\"pident\"]\n",
        ")\n",
        "\n",
        "# extract UniProt accession from sseqid\n",
        "# handles: sp|Q9XXXX|NAME  -> Q9XXXX\n",
        "# also leaves Q9XXXX unchanged if it's already just an accession\n",
        "pssm_df[\"accession\"] = pssm_df[\"sseqid\"].str.split(\"|\").str[1].fillna(pssm_df[\"sseqid\"])\n",
        "\n",
        "print(pssm_df.head(10))\n",
        "print(\"Unique accessions in PSSM hits:\", pssm_df[\"accession\"].nunique())"
      ],
      "metadata": {
        "id": "hpVZ7QqBd9wn",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc54ee5-7876-4c0e-8683-bd6291e82d10"
      },
      "id": "hpVZ7QqBd9wn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [sseqid, qstart, qend, sstart, send, evalue, bitscore, length, pident, accession]\n",
            "Index: []\n",
            "Unique accessions in PSSM hits: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Search result Processing - hmm**"
      ],
      "metadata": {
        "id": "jGJUt6fB44xV"
      },
      "id": "jGJUt6fB44xV"
    },
    {
      "cell_type": "code",
      "source": [
        "# now exctracting hmm hits\n",
        "import pandas as pd\n",
        "\n",
        "hmm_path = f\"{data_dir}/data/O43099_hmm_vs_swissprot.domtbl\"\n",
        "\n",
        "rows = []\n",
        "with open(hmm_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        if line.startswith(\"#\") or not line.strip():\n",
        "            continue\n",
        "        parts = line.strip().split()\n",
        "        rows.append(parts[:22])  # fixed domtbl columns\n",
        "\n",
        "hmm_df = pd.DataFrame(rows)\n",
        "\n",
        "# column 0 = target name (often like sp|Q9XXXX|NAME)\n",
        "hmm_df = hmm_df.rename(columns={0: \"tname\"})\n",
        "\n",
        "# extract UniProt accession\n",
        "hmm_df[\"accession\"] = hmm_df[\"tname\"].str.split(\"|\").str[1].fillna(hmm_df[\"tname\"])\n",
        "\n",
        "print(hmm_df[[\"tname\", \"accession\"]].head(10))\n",
        "print(\"Unique accessions in HMM hits:\", hmm_df[\"accession\"].nunique())"
      ],
      "metadata": {
        "id": "wkclrMpyhUWg",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "296455c3-0b41-47d4-8956-1096acf72696"
      },
      "id": "wkclrMpyhUWg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/BioInformatics/final/data/O43099_hmm_vs_swissprot.domtbl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-780922152.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/BioInformatics/final/data/O43099_hmm_vs_swissprot.domtbl'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparing Ground Truth with our models - Protein Level**"
      ],
      "metadata": {
        "id": "cJJm_lVxd8l9"
      },
      "id": "cJJm_lVxd8l9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ground Truth Set up"
      ],
      "metadata": {
        "id": "3evsrm0rqk3j"
      },
      "id": "3evsrm0rqk3j"
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting ground truth at protein level\n",
        "pfam_id = \"PF08534\"\n",
        "\n",
        "all_swissprot_proteins = set(df[0])\n",
        "\n",
        "gt_proteins = set(df.loc[df[3] == pfam_id, 0])\n",
        "\n",
        "print(\"Total SwissProt proteins:\", len(all_swissprot_proteins))\n",
        "print(f\"Ground truth proteins ({pfam_id}):\", len(gt_proteins))\n"
      ],
      "metadata": {
        "id": "aFmvjeUJ7pxV"
      },
      "id": "aFmvjeUJ7pxV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming MOdel Predictions to protein sets\n",
        "# Model predictions at PROTEIN level\n",
        "pssm_proteins = set(pssm_df[\"accession\"])\n",
        "hmm_proteins  = set(hmm_df[\"accession\"])\n",
        "\n",
        "print(\"Unique PSSM proteins:\", len(pssm_proteins))\n",
        "print(\"Unique HMM proteins:\", len(hmm_proteins))\n"
      ],
      "metadata": {
        "id": "kUailjWb73B1"
      },
      "id": "kUailjWb73B1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up Confusion Matrix\n",
        "def protein_level_confusion(pred_proteins, gt_proteins, universe_proteins):\n",
        "    TP = len(pred_proteins & gt_proteins)\n",
        "    FP = len(pred_proteins - gt_proteins)\n",
        "    FN = len(gt_proteins - pred_proteins)\n",
        "    TN = len(universe_proteins - (pred_proteins | gt_proteins))\n",
        "    return TP, FP, FN, TN\n"
      ],
      "metadata": {
        "id": "6g5JBHOQ8FE9"
      },
      "id": "6g5JBHOQ8FE9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Confusion mAtrices for hmm and pssm"
      ],
      "metadata": {
        "id": "QuTVYwz2A1tx"
      },
      "id": "QuTVYwz2A1tx"
    },
    {
      "cell_type": "code",
      "source": [
        "TP_pssm, FP_pssm, FN_pssm, TN_pssm = protein_level_confusion(\n",
        "    pssm_proteins, gt_proteins, all_swissprot_proteins\n",
        ")\n",
        "\n",
        "print(\"PSSM Confusion Matrix (Protein Level)\")\n",
        "print(\"TP:\", TP_pssm, \"FP:\", FP_pssm, \"FN:\", FN_pssm, \"TN:\", TN_pssm)"
      ],
      "metadata": {
        "id": "GCkXmIZz8LEy"
      },
      "id": "GCkXmIZz8LEy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP_hmm, FP_hmm, FN_hmm, TN_hmm = protein_level_confusion(\n",
        "    hmm_proteins, gt_proteins, all_swissprot_proteins\n",
        ")\n",
        "\n",
        "print(\"HMM Confusion Matrix (Protein Level)\")\n",
        "print(\"TP:\", TP_hmm, \"FP:\", FP_hmm, \"FN:\", FN_hmm, \"TN:\", TN_hmm)"
      ],
      "metadata": {
        "id": "w478RfWI8QOz"
      },
      "id": "w478RfWI8QOz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision Matrices first set up and then in the next cell computed"
      ],
      "metadata": {
        "id": "0oG1SFn58gou"
      },
      "id": "0oG1SFn58gou"
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def compute_metrics(TP, FP, FN, TN):\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "    f1 = (2 * precision * recall / (precision + recall)\n",
        "          if (precision + recall) > 0 else 0)\n",
        "\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "    balanced_accuracy = (recall + specificity) / 2\n",
        "\n",
        "    denominator = math.sqrt((TP + FP)*(TP + FN)*(TN + FP)*(TN + FN))\n",
        "    mcc = ((TP * TN - FP * FN) / denominator\n",
        "           if denominator > 0 else 0)\n",
        "\n",
        "    return {\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-score\": f1,\n",
        "        \"Balanced Accuracy\": balanced_accuracy,\n",
        "        \"MCC\": mcc\n",
        "    }\n"
      ],
      "metadata": {
        "id": "jSMJlbQO8gSz"
      },
      "id": "jSMJlbQO8gSz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pssm_metrics = compute_metrics(TP_pssm, FP_pssm, FN_pssm, TN_pssm)\n",
        "\n",
        "print(\"PSSM – Protein Level Metrics\")\n",
        "for k, v in pssm_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "hqRRmEmO8m2X"
      },
      "id": "hqRRmEmO8m2X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hmm_metrics = compute_metrics(TP_hmm, FP_hmm, FN_hmm, TN_hmm)\n",
        "\n",
        "print(\"HMM – Protein Level Metrics\")\n",
        "for k, v in hmm_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "PA_yC3338sqK"
      },
      "id": "PA_yC3338sqK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparing the Models - Domain Level**"
      ],
      "metadata": {
        "id": "2x7w5BThuAMZ"
      },
      "id": "2x7w5BThuAMZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Pfam (ground truth) domains with start/end\n",
        "import pandas as pd\n",
        "\n",
        "# df is already loaded from protein2ipr_sprot.dat in your notebook\n",
        "# pfam_id is already set (e.g., \"PF08534\")\n",
        "\n",
        "pfam_rows = df[df[3] == pfam_id].copy()\n",
        "\n",
        "# auto-detect start/end columns (take the last two numeric-like columns)\n",
        "num_cols = []\n",
        "for c in pfam_rows.columns:\n",
        "    col = pd.to_numeric(pfam_rows[c], errors=\"coerce\")\n",
        "    if col.notna().mean() > 0.9:\n",
        "        num_cols.append(c)\n",
        "\n",
        "start_col, end_col = num_cols[-2], num_cols[-1]\n",
        "\n",
        "pfam_domains = pfam_rows[[0, start_col, end_col]].copy()\n",
        "pfam_domains.columns = [\"accession\", \"pfam_start\", \"pfam_end\"]\n",
        "\n",
        "pfam_domains[\"pfam_start\"] = pfam_domains[\"pfam_start\"].astype(int)\n",
        "pfam_domains[\"pfam_end\"]   = pfam_domains[\"pfam_end\"].astype(int)\n",
        "\n",
        "print(pfam_domains.head())\n",
        "print(\"Pfam domain rows:\", len(pfam_domains))\n",
        "print(\"Pfam proteins (residue-level GT):\", pfam_domains[\"accession\"].nunique())\n"
      ],
      "metadata": {
        "id": "6MPqEMsqz6Yr"
      },
      "id": "6MPqEMsqz6Yr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute protein length\n",
        "from Bio import SeqIO\n",
        "\n",
        "protein_lengths = {}\n",
        "for rec in SeqIO.parse(\"uniprot_sprot.fasta\", \"fasta\"):\n",
        "    parts = rec.id.split(\"|\")\n",
        "    acc = parts[1] if len(parts) > 1 else rec.id\n",
        "    protein_lengths[acc] = len(rec.seq)\n",
        "\n",
        "print(\"Protein lengths loaded:\", len(protein_lengths))\n",
        "\n"
      ],
      "metadata": {
        "id": "82BR_9S0uKIU"
      },
      "id": "82BR_9S0uKIU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the residue set from pfam for the true negative clalculation\n",
        "pfam_residues = {}\n",
        "for _, row in pfam_domains.iterrows():\n",
        "    acc = row[\"accession\"]\n",
        "    lo, hi = sorted((int(row[\"pfam_start\"]), int(row[\"pfam_end\"])))\n",
        "    pfam_residues.setdefault(acc, set()).update(range(lo, hi + 1))\n",
        "\n",
        "print(\"Pfam residue proteins:\", len(pfam_residues))\n"
      ],
      "metadata": {
        "id": "rs5Ub0uhkcqT"
      },
      "id": "rs5Ub0uhkcqT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting PSSM Residues\n"
      ],
      "metadata": {
        "id": "75Gp2ncDug34"
      },
      "id": "75Gp2ncDug34"
    },
    {
      "cell_type": "code",
      "source": [
        "# build residue-level predictions for PSSM\n",
        "# Predictions (PSSM): union if multiple alignments per protein\n",
        "pssm_domains = pssm_df.copy()\n",
        "\n",
        "pssm_residues = {}\n",
        "for _, row in pssm_domains.iterrows():\n",
        "    acc = row[\"accession\"]\n",
        "    lo, hi = sorted((int(row[\"sstart\"]), int(row[\"send\"])))\n",
        "    pssm_residues.setdefault(acc, set()).update(range(lo, hi + 1))\n",
        "\n",
        "print(\"PSSM residue proteins:\", len(pssm_residues))\n",
        "\n",
        "# inspect the same example protein if present\n",
        "acc = \"A5F3A2\"\n",
        "print(\"Has PSSM prediction for A5F3A2?\", acc in pssm_residues)\n",
        "if acc in pssm_residues:\n",
        "    print(\"Number of PSSM predicted residues:\", len(pssm_residues[acc]))\n",
        "    print(\"First 10 predicted residues:\", list(sorted(pssm_residues[acc]))[:10])\n",
        "    print(\"Last 10 predicted residues:\", list(sorted(pssm_residues[acc]))[-10:])\n"
      ],
      "metadata": {
        "id": "twAiZhLhyw5P"
      },
      "id": "twAiZhLhyw5P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting hmm Residues"
      ],
      "metadata": {
        "id": "gj-aii82DDJj"
      },
      "id": "gj-aii82DDJj"
    },
    {
      "cell_type": "code",
      "source": [
        "# build residue-level predictions for hmm\n",
        "# assign proper domtblout column names\n",
        "\n",
        "\n",
        "domtbl_cols = [\n",
        "    \"tname\",\"taccession\",\"tlen\",\n",
        "    \"qname\",\"qaccession\",\"qlen\",\n",
        "    \"full_evalue\",\"full_score\",\"full_bias\",\n",
        "    \"dom_num\",\"dom_of\",\n",
        "    \"c_evalue\",\"i_evalue\",\"dom_score\",\"dom_bias\",\n",
        "    \"hmm_from\",\"hmm_to\",\n",
        "    \"ali_from\",\"ali_to\",\n",
        "    \"env_from\",\"env_to\",\n",
        "    \"acc\"\n",
        "]\n",
        "\n",
        "# rename numeric columns (1..21) -> the expected domtblout names excluding tname\n",
        "rename_map = {i: domtbl_cols[i] for i in range(1, 22)}  # 1..21\n",
        "hmm_df = hmm_df.rename(columns=rename_map)\n",
        "\n",
        "# ensure accession exists (you already created it earlier; keep it)\n",
        "if \"accession\" not in hmm_df.columns:\n",
        "    hmm_df[\"accession\"] = hmm_df[\"tname\"].astype(str)\n",
        "\n",
        "print(\"hmm_df columns after renaming:\")\n",
        "print(list(hmm_df.columns))\n",
        "\n",
        "# now build residue sets using ali_from/ali_to (target alignment coords)\n",
        "hmm_residues = {}\n",
        "for _, row in hmm_df.iterrows():\n",
        "    acc = row[\"accession\"]\n",
        "    lo, hi = sorted((int(row[\"ali_from\"]), int(row[\"ali_to\"])))\n",
        "    hmm_residues.setdefault(acc, set()).update(range(lo, hi + 1))\n",
        "\n",
        "print(\"HMM residue proteins:\", len(hmm_residues))\n"
      ],
      "metadata": {
        "id": "bB8O7CAm-yDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46618570-0ae9-4220-8e83-94d066a63933"
      },
      "id": "bB8O7CAm-yDZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hmm_df columns after renaming:\n",
            "['tname', 'taccession', 'tlen', 'qname', 'qaccession', 'qlen', 'full_evalue', 'full_score', 'full_bias', 'dom_num', 'dom_of', 'c_evalue', 'i_evalue', 'dom_score', 'dom_bias', 'hmm_from', 'hmm_to', 'ali_from', 'ali_to', 'env_from', 'env_to', 'acc', 'accession']\n",
            "HMM residue proteins: 226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PSSM - Residue Level Confusion Matrix - Domain Level"
      ],
      "metadata": {
        "id": "lfi1KGRTzKNq"
      },
      "id": "lfi1KGRTzKNq"
    },
    {
      "cell_type": "code",
      "source": [
        "#pssm confusion matrix\n",
        "TP_res_pssm = FP_res_pssm = FN_res_pssm = TN_res_pssm = 0\n",
        "\n",
        "for acc, pfam_set in pfam_residues.items():\n",
        "    pred_set = pssm_residues.get(acc, set())\n",
        "\n",
        "    TP = len(pfam_set & pred_set)\n",
        "    FP = len(pred_set - pfam_set)\n",
        "    FN = len(pfam_set - pred_set)\n",
        "\n",
        "    L = protein_lengths.get(acc)\n",
        "    if L is None:\n",
        "        continue\n",
        "\n",
        "    TN = L - (TP + FP + FN)\n",
        "    if TN < 0:\n",
        "        continue\n",
        "\n",
        "    TP_res_pssm += TP\n",
        "    FP_res_pssm += FP\n",
        "    FN_res_pssm += FN\n",
        "    TN_res_pssm += TN\n",
        "\n",
        "\n",
        "print(\"PSSM Confusion Matrix (Residue Level)\")\n",
        "print(\"TP:\", TP_res_pssm,\n",
        "      \"FP:\", FP_res_pssm,\n",
        "      \"FN:\", FN_res_pssm,\n",
        "      \"TN:\", TN_res_pssm)"
      ],
      "metadata": {
        "id": "vH0aBz7ZzJzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44342e7-3a04-45ff-c4ab-8cae31ba3f26"
      },
      "id": "vH0aBz7ZzJzW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSSM Confusion Matrix (Residue Level)\n",
            "TP: 6106 FP: 168 FN: 9190 TN: 5444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HMM – Residue Level Confusion Matrice\n",
        "\n",
        "TP_res_hmm = FP_res_hmm = FN_res_hmm = TN_res_hmm = 0\n",
        "\n",
        "for acc, pfam_set in pfam_residues.items():\n",
        "    pred_set = hmm_residues.get(acc, set())\n",
        "\n",
        "    TP = len(pfam_set & pred_set)\n",
        "    FP = len(pred_set - pfam_set)\n",
        "    FN = len(pfam_set - pred_set)\n",
        "\n",
        "    L = protein_lengths.get(acc)\n",
        "    if L is None:\n",
        "        continue\n",
        "\n",
        "    TN = L - (TP + FP + FN)\n",
        "    if TN < 0:\n",
        "        continue\n",
        "\n",
        "    TP_res_hmm += TP\n",
        "    FP_res_hmm += FP\n",
        "    FN_res_hmm += FN\n",
        "    TN_res_hmm += TN\n",
        "\n",
        "\n",
        "print(\"HMM Confusion Matrix (Residue Level)\")\n",
        "print(\"TP:\", TP_res_hmm,\n",
        "      \"FP:\", FP_res_hmm,\n",
        "      \"FN:\", FN_res_hmm,\n",
        "      \"TN:\", TN_res_hmm)\n"
      ],
      "metadata": {
        "id": "z2Hy3OV5_TLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3ff6f0-4635-4d10-ed9f-d9a5c25d18ef"
      },
      "id": "z2Hy3OV5_TLa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HMM Confusion Matrix (Residue Level)\n",
            "TP: 6242 FP: 108 FN: 9054 TN: 5504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Precision Set up generic\n",
        "import math\n",
        "\n",
        "def compute_metrics(TP, FP, FN, TN):\n",
        "    precision = TP / (TP + FP) if (TP + FP) else 0.0\n",
        "    recall    = TP / (TP + FN) if (TP + FN) else 0.0\n",
        "    f1        = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0.0\n",
        "    bal_acc   = 0.5 * (\n",
        "        (TP / (TP + FN) if (TP + FN) else 0.0) +\n",
        "        (TN / (TN + FP) if (TN + FP) else 0.0)\n",
        "    )\n",
        "    denom = (TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)\n",
        "    mcc = ((TP * TN - FP * FN) / math.sqrt(denom)) if denom else 0.0\n",
        "    return {\"Precision\": precision, \"Recall\": recall, \"F1-score\": f1, \"Balanced Accuracy\": bal_acc, \"MCC\": mcc}\n"
      ],
      "metadata": {
        "id": "V5sUgT0X_3hS"
      },
      "id": "V5sUgT0X_3hS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Precision Calculation for both models\n",
        "pssm_res_metrics = compute_metrics(TP_res_pssm, FP_res_pssm, FN_res_pssm, TN_res_pssm)\n",
        "hmm_res_metrics  = compute_metrics(TP_res_hmm,  FP_res_hmm,  FN_res_hmm,  TN_res_hmm)\n",
        "\n",
        "print(\"PSSM – Residue Level Metrics\")\n",
        "for k, v in pssm_res_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "print(\"\\nHMM – Residue Level Metrics\")\n",
        "for k, v in hmm_res_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "f1-9sXHv_7Tg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f7cd50-6399-4f12-902d-74b4cb71705e"
      },
      "id": "f1-9sXHv_7Tg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSSM – Residue Level Metrics\n",
            "Precision: 0.9732\n",
            "Recall: 0.3992\n",
            "F1-score: 0.5662\n",
            "Balanced Accuracy: 0.6846\n",
            "MCC: 0.3570\n",
            "\n",
            "HMM – Residue Level Metrics\n",
            "Precision: 0.9830\n",
            "Recall: 0.4081\n",
            "F1-score: 0.5767\n",
            "Balanced Accuracy: 0.6944\n",
            "MCC: 0.3747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Retreive the Family Sequence**"
      ],
      "metadata": {
        "id": "htUpqExOuNYP"
      },
      "id": "htUpqExOuNYP"
    },
    {
      "cell_type": "code",
      "source": [
        "# write verified family FASTA directly\n",
        "from Bio import SeqIO\n",
        "\n",
        "verified_accessions = set(verified[\"accession\"])\n",
        "verified_fasta_path = f\"{data_dir}/data/O43099_verified_family.fasta\"\n",
        "\n",
        "n_written = 0\n",
        "with open(verified_fasta_path, \"w\") as out:\n",
        "    for rec in SeqIO.parse(out_file, \"fasta\"):\n",
        "        if extract_accession(rec.id) in verified_accessions:\n",
        "            SeqIO.write(rec, out, \"fasta\")\n",
        "            n_written += 1\n",
        "\n",
        "print(\"✅ Verified family FASTA written to:\")\n",
        "print(verified_fasta_path)\n",
        "print(\"Sequences exported:\", n_written)\n"
      ],
      "metadata": {
        "id": "X4Kw_czKD0SF"
      },
      "id": "X4Kw_czKD0SF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}